{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Education Module_002.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaisalUllahKhan/IIOT/blob/master/Education_Module_002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4b2meI2LQgs",
        "colab_type": "text"
      },
      "source": [
        "# 1. Networking for IIOT\n",
        "\n",
        "### Contents:\n",
        "- [Overview](#Overview)\n",
        "- [IIOT End Devices](#IIOT-End-Devices)\n",
        "    - [Introduction to some protocols](#Introduction-to-some-protocols)\n",
        "    - [Sensors](#Sensors)\n",
        "- [IIOT Gateways](#IIOT-Gateways)\n",
        "    - [Services running on Raspberry](#Services-running-on-Raspberry)\n",
        "    - [Setting up the pi](#Setting-up-the-Pi)\n",
        "        - [OS](#OS)\n",
        "        - [Username and password](#Username-and-password)\n",
        "        - [Mosquitto broker](#Mosquitto-broker)\n",
        "        - [Setting up Internet Connectivity](#Setting-up-Internet-Connectivity)\n",
        "- [IIOT Middleware](#IIOT-Middleware)\n",
        "    - [Setting up Elasticsearch](#Setting-up-Elasticsearch)\n",
        "    - [Setting up Kibana](#Setting-up-Kibana)\n",
        "    - [Kibana Aggregations](#Kibana-Aggregations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzaNj-XjLQg2",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "***\n",
        "### Functional Layers in IIOT Network implementation\n",
        "***\n",
        "> 1. IIOT End Devices - IED\n",
        "> 2. IIOT Gateways - IGW\n",
        "> 3. IIOT Middleware - IMW\n",
        "> 4. IIOT Cloud Server - ICS\n",
        "\n",
        "#### IIOT END DEVICES(IED)\n",
        "***\n",
        "- The IoT end-devices or IEDs contain the sensors (or actuators) and are closest to the end node being monitored. They gather data periodically by reading the sensors attached to them and relay them to the IOT Gateway over a suitable protocol/channel like MODBUS, BLE, or directly over the GPIO pins depending on the type of sensor\n",
        "- Different type of sensors connect differently to the Gateways, like we can connect:\n",
        "    - Vibration sensor over Bluetooth(BLE)\n",
        "    - Energy Meter over MODBUS\n",
        "    - Proximity Sensor over GPIOS of RpiZ\n",
        "    - Thermocouple Temperature Sensor over I2C\n",
        "    \n",
        "#### IIOT GATEWAYS(IGW)\n",
        "***\n",
        "- The gateways are devices which are next up in the hierarchy of the network.\n",
        "- The gateways provide the following services:\n",
        "    1. **Reliable Connectivity:** between the IIOT Server and the IIOT End Devices. The IGW may buffer the incoming data from various IEDs incase the upstream connection to the IMW is broken and try to push the data once the IMW is reachable again.\n",
        "    2. **Protocol and data bridge:** makes possible the interoperation of IEDs using different protocols and data formats - i.e. a Sensor might be sending reading of LDR analog values using plain text over UART Serial and the IGW can translate the same to a JSON message which might be then sent to the IMW. Similarly an Energy meter might be using a protocol like MODBUS to convey the sensor readings and the IGW will translate the MODBUS formatted datapacket into a JSON message to be sent to the IMW. Similarly JSON commands sent to IEDs containing actuators may be converted to the proper data format and protocol by the IGW before forwarded to the IED.\n",
        "    3. **Management:** The gateway can automatically detect and add new IEDs added to the network or remove faulty IEDs from the network intelligently. In this way the IEDs can be managed via the IGW.\n",
        "    4. **Storage and Analysis:** In certain cases, the IGW can itself act as a data store and can also perform lightweight analysis on the incomming data and push only the very relevant information to the IMW and filtering out the rest. Also the IGW can take certain actions like commanding an actuator based on the analysis of the incoming sensor data and hence the closed loop time to take critical actions can be reduced.\n",
        " \n",
        "#### IIOT MIDDLEWARE(IMW)\n",
        "***\n",
        "- Next up in the network is the IIOT Middleware which provides the following services in general (which may vary slightly between implementations:\n",
        "    - **Persistent data storage**\n",
        "    - **Analysis on the data**\n",
        "    - **Automated provisioning** (discovery and removal) of IIOT gateways\n",
        "    \n",
        "####  IIOT Cloud Server (ICS)\n",
        "- The final layer in the network is the cloud server.\n",
        "- This server has a public IPv4 and/or IPv6 address and is reachable from anywhere on the internet.\n",
        "- The cloud server can be used for -\n",
        "    - permanent data store\n",
        "    - online/offline analysis\n",
        "    - realtime visualisation of the raw/processed data\n",
        "    - VPN access to the Middleware and the local network in the remote factory floor\n",
        "\n",
        "#### OVERVIEW DIAGRAM\n",
        "***\n",
        "![IOTGW-OVERVIEW.jpg](attachment:IOTGW-OVERVIEW.jpg)\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTD2BdJ8LQg6",
        "colab_type": "text"
      },
      "source": [
        "## IIOT End Devices\n",
        "***\n",
        "![IOTGW-OVERVIEW-HIGHLIGHT-IED.png](attachment:IOTGW-OVERVIEW-HIGHLIGHT-IED.png)\n",
        "\n",
        "- The end devices are those devices that take data from the machines directly or indirectly and send that data via a network to the observer, to make evaluations and optimizations based on that data.\n",
        "- The raw data can be converted to a desired format and we can run any desired analytics on that data.\n",
        "- The main objective is that using this data we should be able to increase the efficiency of machines, by reducing the energy consumed and reducing the idle time of machines if possible and also we could make a digital twin for the owner to see in real time.\n",
        "- The sensors are the end devices in our implementations\n",
        "- An Arduino board can also be used as an end device that will interact with the sensors and the IGW\n",
        "- As already mentioned in the overview we can use different methods for interacting the sensors with the IGW like:\n",
        "    - Vibration sensor over BLE\n",
        "    - Energy Meter over MODBUS\n",
        "    - Proximity sensor over GPIOs of RPiZ\n",
        "    - Thermocouple Temperature Sensor over I2C\n",
        "\n",
        "### Introduction to some protocols\n",
        "***\n",
        "**Bluetooth Low Energy(BLE)**\n",
        "- Not actually a protocol\n",
        "- is a wireless personal area network technology\n",
        "- Compared to Classic Bluetooth, Bluetooth Low Energy is intended to provide considerably reduced power consumption and cost while maintaining a similar communication range. \n",
        "- Bluetooth Low Energy uses the same 2.4 GHz radio frequencies as classic Bluetooth\n",
        "- It offers very low power consumption and hence battery life can be very long. \n",
        "- It can not be used for higher data rates as offered by wifi and cellular technologies.\n",
        "- For more details [click here](https://en.wikipedia.org/wiki/Bluetooth_Low_Energy)\n",
        "\n",
        "**MODBUS**\n",
        "- Modbus is a communication protocol developed by Modicon systems. In simple terms, it is a method used for transmitting information over serial lines between electronic devices. The device requesting the information is called the Modbus Master and the devices supplying information are Modbus Slaves\n",
        "- For more details [click here](https://en.wikipedia.org/wiki/Modbus)\n",
        "\n",
        "**I2C**\n",
        "- I2C is a serial communication protocol, so data is transferred bit by bit along a single wire (the SDA line). Like SPI, I2C is synchronous, so the output of bits is synchronized to the sampling of bits by a clock signal shared between the master and the slave. The clock signal is always controlled by the master.\n",
        "- For more details [click here](http://www.circuitbasics.com/basics-of-the-i2c-communication-protocol/)\n",
        "\n",
        "### Sensors\n",
        "***\n",
        "\n",
        "**Vibration Sensor**\n",
        "\n",
        "- As mentioned above we usually connect the vibration sensor to our IGW ie RPiZ using BLE\n",
        "- The vibration sensor is also called a piezoelectric sensor. These sensors are flexible devices which are used for measuring various processes. This sensor uses the piezoelectric effects while measuring the changes within acceleration, pressure, temperature, force otherwise strain by changing to an electrical charge. \n",
        "![Vibration%20Sensor.jpg](attachment:Vibration%20Sensor.jpg)\n",
        "\n",
        "**Proximity Sensor**\n",
        "\n",
        "- A proximity sensor is a sensor able to detect the presence of nearby objects without any physical contact. A proximity sensor often emits an electromagnetic field or a beam of electromagnetic radiation (infrared, for instance), and looks for changes in the field or return signal.\n",
        "![Proximity%20sensor.jpg](attachment:Proximity%20sensor.jpg)\n",
        "\n",
        "**Energy Meter**\n",
        "\n",
        "- Energy Meter Definition: The meter which is used for measuring the energy utilises by the electric load is known as the energy meter. The energy is the total power consumed and utilised by the load at a particular interval of time. It is used in domestic and industrial AC circuit for measuring the power consumption.\n",
        "![Energy%20Meter1.png](attachment:Energy%20Meter1.png)\n",
        "\n",
        "**Temperature Sensor**\n",
        "\n",
        "- Temperature sensor is a device, to measure the temperature through an electrical signal it requires a thermocouple or RTD (Resistance Temperature Detectors). The thermocouple is prepared by two dissimilar metals which generate the electrical voltage indirectly proportional to change the temperature. The RTD is a VARIABLE RESISTENCE , it will change the electrical resistance indirectly proportional to changes in the temperature in a precise, and nearly linear manner.\n",
        "![Temp%20Sensor.jpg](attachment:Temp%20Sensor.jpg)\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crFy00KTLQg-",
        "colab_type": "text"
      },
      "source": [
        "## IIOT Gateways\n",
        "***\n",
        "![IOTGW-OVERVIEW-HIGHLIGHT-GW.png](attachment:IOTGW-OVERVIEW-HIGHLIGHT-GW.png)\n",
        "***\n",
        "- The IIOT gateway in our implementation is a Raspberry Pi-zero-W which is a small Single Board Computer (SBC).\n",
        "- The RPiZw runs a Debian OS(Raspbian) which is similar to the Ubuntu/Linux OS we use in our desktop.\n",
        "- Many softwares are run on the RPiZw which enable the RPiZw to provide the necessary services needed to be present on a IIOT Gateway.\n",
        "- To read more about the pi [click here](https://www.raspberrypi.org/documentation/)\n",
        "\n",
        "### Services running on Raspberry\n",
        "***\n",
        "1. IIOT End Device Driver (IED Driver)\n",
        "2. Mosquitto MQTT Broker\n",
        "3. MQTT to IIOT Middleware Publish Service.\n",
        "\n",
        "**The diagram below shows the microservices running on the Raspberry Pi**\n",
        "***\n",
        "![IOTGW-DETAILS.jpg](attachment:IOTGW-DETAILS.jpg)\n",
        "\n",
        "### Setting up the Pi\n",
        "***\n",
        "### OS\n",
        "***\n",
        "- We need to install the Raspbian OS or NOOBS on the pi which is very similar to the Linux distributions\n",
        "- For our purposes we will use the Raspbian OS\n",
        "- You can download it from [here](https://www.ra+spberrypi.org/downloads/raspbian/)\n",
        "***\n",
        "![Raspbian.png](attachment:Raspbian.png)\n",
        "***\n",
        "- After the ISO image has been downloaded on our Pc we need to burn the image on a memory card(16GB) to be used in the Pi\n",
        "- You can use [Win32 disk imager](https://sourceforge.net/projects/win32diskimager/) to burn the image\n",
        "- We can also include the drivers on the image before burning it to an SD card, so that our end devices can interact with our Pi\n",
        "***\n",
        "### Username and password\n",
        "***\n",
        "- By default the username of the pi is 'pi' and the password is 'raspberry'.\n",
        "- So the first thing we might want to do is to change these defaults for security reasons.\n",
        "- After connecting our pi to a monitor and other peripherals we can easily change the username and password and also create additional users if necessary.\n",
        "\n",
        "-  In the command line type raspi-config and hit enter we will see a menu pop up!\n",
        "\n",
        "\n",
        "![raspi-config-password.png](attachment:raspi-config-password.png)\n",
        "\n",
        "- Simply select the change password option and type in the new password \n",
        "Or we can also simply type \"passwd\" to change the password of the current user\n",
        "\n",
        "- In order to change the username 'pi' we will have to log in a the root user since it's not possible to rename an account while your logged into it. To log in as root user first we have to enable it, to do so type the following command whilst logged in as the default pi user:\n",
        "\n",
        ">``` sudo passwd root```\n",
        "\n",
        "- Choose a secure password for the root user. You can disable the root account later if you wish.\n",
        "\n",
        "- Now logout of the user pi using the command:\n",
        "\n",
        ">logout\n",
        "\n",
        "- And then logout back in as the user 'root' using the password you just created. Now we can rename the the default pi user name. The following method renames the user 'pi' to 'newname', replace this with whatever you want. Type the command:\n",
        "\n",
        "> usermod -l newname pi\n",
        "\n",
        "- Now the user name has been changed the user's home directory name should also be changed to \n",
        "reflect the new login name:\n",
        "\n",
        "> usermod -m -d /home/newname newname\n",
        "\n",
        "- Now logout and login back in as newname. You can change the default password from raspberry to something more secure by typing following command and entering a new password when prompted:\n",
        "\n",
        "> passwd\n",
        "\n",
        "- If you wish you can disable the root user account again but first double check newname still has 'sudo' privileges. Check the following update command works:\n",
        "\n",
        "> sudo apt-get update\n",
        "\n",
        "- If it works then you can disable the root account by locking the password:\n",
        "\n",
        "> sudo passwd -l root\n",
        "***\n",
        "### Mosquitto broker\n",
        "***\n",
        "![IOTGW-DETAILS-HIGHLIGHT-MQTTBROKER.png](attachment:IOTGW-DETAILS-HIGHLIGHT-MQTTBROKER.png)\n",
        "***\n",
        "- To download and setup the mosquitto mqtt broker visit the following link: [Mosquitto Broker](https://mosquitto.org/download/)\n",
        "- Follow the instructions specific to your OS\n",
        "- After installation to start the mosquitto service type: <font color = red>sudo service mosquitto start</font> for linux\n",
        "- For illustration you may use the terminal to subscribe to a topic and see the sensor data being published to that topic(python/sin6) in this case\n",
        "- We use python code to publish the sensor data to the MQTT topic\n",
        "- Another Python code subscribes to the topic and then pushes the data to the Database\n",
        "- A **sample python code** to illustrate the publishing of data to an MQTT topic is as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV8gU7oLLQhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import paho.mqtt.client as mqttClient\n",
        "import datetime\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plot\n",
        "\n",
        "def on_connect(client, userdata, flags, rc):\n",
        " \n",
        "    if rc == 0:\n",
        " \n",
        "        print(\"Connected to broker\")\n",
        " \n",
        "        global Connected                #Use global variable\n",
        "        Connected = True                #Signal connection \n",
        " \n",
        "    else:\n",
        " \n",
        "        print(\"Connection failed\")\n",
        "    \n",
        "Connected = False\n",
        "\n",
        "client = mqttClient.Client()                       #create new instance\n",
        "# client.username_pw_set(user, password=password)  #set username and password\n",
        "client.on_connect= on_connect                      #attach function to callback\n",
        "client.connect(\"localhost\", port=1883)             #connect to broker\n",
        "client.loop_start()                                #start the loop\n",
        "\n",
        "\n",
        "# publishing a sine wave to an MQ\n",
        "# Get x values of the sine wave\n",
        "time1= np.arange(0, 10, 0.1); \n",
        "# Amplitude of the sine wave is sine of a variable like time\n",
        "amplitude=np.sin(time1)\n",
        "\n",
        "# while Connected != True:    #Wait for connection\n",
        "#     time.sleep(0.1)\n",
        "\n",
        "try:\n",
        "        \n",
        "    for i in range(100):\n",
        "        value = amplitude[i]\n",
        "        client.publish(\"python/sin6\",value)\n",
        "        time.sleep(1)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print('stop it')\n",
        "client.disconnect()\n",
        "client.loop_stop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWmVPEKDLQhT",
        "colab_type": "text"
      },
      "source": [
        "- You must now be able to see the values being published in the terminal.\n",
        "- Also in the next section we will use a python code to subscribe to this topic and then push the data to the Database \n",
        "***\n",
        "### Setting up Internet Connectivity\n",
        "***\n",
        "- This is only for a wireless connection\n",
        "- Alternatively we can simply connect an ehternet cable\n",
        "- Navigate to wpa_supplicant:\n",
        "> sudo nano /etc/wpa_supplicant/wpa_supplicant config\n",
        "- Then at the bottom of the file we can add our wireless network \n",
        "> network={ <br>\n",
        "ssid = \"testing\" <br>\n",
        "psk = \"testing passwd\" <br>\n",
        "}\n",
        "***\n",
        "### Providing a Static IP to the RPi\n",
        "***\n",
        "There are two ways of achieving this goal:\n",
        "1. Assigning a static IP to Rpi using a router\n",
        "2. Assigning a static IP to RPi with DHCPCD\n",
        "**Here we will only describe the later:**\n",
        "***\n",
        "Raspbian Jessie, or Jessie Lite – the current Raspbian operating systems at the moment – have a DHCP client daemon (DHCPCD) that can communicate with the DHCP servers from routers. The configuration file of a DHCP client daemon allows you to change the private IP address of a computer and set it up in the long term. The following instructions will assign a static IPv4 address with 32 bits (not to be confused with an IPv6 address, which has 128 bits available) to the Raspberry Pi.\n",
        "\n",
        "Before you begin with the assignment of a private IP address for Raspberry Pi, check whether DHCPCD is already activated using the following command:\n",
        "> sudo service dhcpcd status\n",
        "\n",
        "In case it’s not, activate DHCPCD as follows:\n",
        ">sudo service dhcpcd start<br>\n",
        "sudo systemctl enable dhcpcd\n",
        "\n",
        "Now make sure that the configuration of the file /etc/network/interfaces has the original status. For this, the ‘iface’ configuration needs to be set at ‘manual’ for the interfaces.\n",
        "\n",
        "For the editing of the activated DHCPCDs, start by opening the configuration file `/etc/dhcpcd.conf` and running the following command:\n",
        "> sudo nano /etc/dhcpcd.conf\n",
        "\n",
        "To assign an IP address to Raspberry Pi, use the command ‘static ip_address=’ followed by the desired IPv4 address and the suffix ‘/24’ (an abbreviation of the subnet mak 255.255.255.0). For example, if you want to link a computer with the IPv4 address 192.168.0.4, then you need to use the command ‘static ip_address=192.168.0.4/24’. It goes without saying that the address used here is not yet used anywhere else. As such, it also can’t be located in the address pool of a DHCP server.\n",
        "\n",
        "You still then need to specify the address of your gateway and domain name server (usually both are the router). Raspberry Pi turns to the gateway address if an IP address to which it wants to send something is outside of the subnet mask (in the example, this would mean outside of the range 192.168.0). In the following command, the IPv4 address 192.168.0.1 is used as an example as both the gateway and DNS server. The complete command looks like this in our example (where a network cable is used for the internet connection):\n",
        "> interface eth0<br>\n",
        "static ip_address=192.168.0.4/24<br>\n",
        "static routers=192.168.0.1<br>\n",
        "static domain_name_servers=192.168.0.1<br>\n",
        "\n",
        "The command lines above match the IPv4 addresses that you want to use for your Raspberry Pi, or where your router is assigned. Save the changes with ‘Ctrl + O’ and then press the enter key. Close the configuration file with ‘Ctrl + X’. Restart to adopt the newly assigned static IP address in the network:\n",
        "> sudo reboot\n",
        "\n",
        "Now use a ping command to check whether the Raspberry Pi is accessible in the network with its new IP address:\n",
        "> Ping raspberrypi.local\n",
        "\n",
        "If the connection of the IP address was successful, you’ll see that you can reach it under the new IP address with a ping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkDDpFC7LQhY",
        "colab_type": "text"
      },
      "source": [
        "## IIOT Middleware\n",
        "***\n",
        "![IOTGW-OVERVIEW-HIGHLIGHT-MW.png](attachment:IOTGW-OVERVIEW-HIGHLIGHT-MW.png)\n",
        "***\n",
        "- **Let's setup the components (microservices) of the Middleware**\n",
        "1. Elasticsearch Database and Elasticsearch DB Client Driver using HTTP REST APIs.\n",
        "2. Kibana - to browse the data in the database\n",
        "3. MQTT Client to receive data from MQTT Queue and pass to Elasticsearch REST Client.\n",
        "\n",
        "### Setting up Elasticsearch\n",
        "***\n",
        "- Elasticsearch is a distributed, open source search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. Elasticsearch is built on Apache Lucene and was first released in 2010 by Elasticsearch N.V. (now known as Elastic). Known for its simple REST APIs, distributed nature, speed, and scalability, Elasticsearch is the central component of the Elastic Stack, a set of open source tools for data ingestion, enrichment, storage, analysis, and visualization. Commonly referred to as the ELK Stack (after Elasticsearch, Logstash, and Kibana), the Elastic Stack now includes a rich collection of lightweight shipping agents known as Beats for sending data to Elasticsearch.\n",
        "- To install elasticsearch on your Pc visit the following [link](https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started-install.html)\n",
        "- How does Elasticsearch work?\n",
        "> Raw data flows into Elasticsearch from a variety of sources, including logs, system metrics, and web applications. Data ingestion is the process by which this raw data is parsed, normalized, and enriched before it is indexed in Elasticsearch. Once indexed in Elasticsearch, users can run complex queries against their data and use aggregations to retrieve complex summaries of their data. From Kibana, users can create powerful visualizations of their data, share dashboards, and manage the Elastic Stack.\n",
        "- What is an Elasticsearch index?\n",
        "> An Elasticsearch index is a collection of documents that are related to each other. Elasticsearch stores data as JSON documents. Each document correlates a set of keys (names of fields or properties) with their corresponding values (strings, numbers, Booleans, dates, arrays of values, geolocations, or other types of data).\n",
        "Elasticsearch uses a data structure called an inverted index, which is designed to allow very fast full-text searches. An inverted index lists every unique word that appears in any document and identifies all of the documents each word occurs in.\n",
        "During the indexing process, Elasticsearch stores documents and builds an inverted index to make the document data searchable in near real-time. Indexing is initiated with the index API, through which you can add or update a JSON document in a specific index.\n",
        "\n",
        "- After the installation is complete we need to start the elasticsearch service using the terminal\n",
        "- Type <font color = red>sudo /bin/systemctl enable elasticsearch.service </font> to enable elastic search\n",
        "- Type <font color = red>sudo systemctl start elasticsearch.service</font> to start elastic search service\n",
        "- Type <font color = red>sudo systemctl stop elasticsearch.service</font> to stop elastic search service\n",
        "\n",
        "**Elasticsearch API**\n",
        "Now that we have installed Elasticsearch, let's understand how we can store data in the DB using the REST APIs provided by Elasticsearch.\n",
        "\n",
        "Please visit the link below to read more about REST and HTTP [click here](https://code.tutsplus.com/tutorials/a-beginners-guide-to-http-and-rest--net-16340)\n",
        "\n",
        "1. REST APIs use HTTP to query,insert, update and delete data from the DB.\n",
        "2. HTTP is the protocol that makes the World Wide Web possible.\n",
        "3. Everytime we visit a page in a Web Browser, the browser makes a HTTP GET request to fetch the page.\n",
        "4. Also, everytime we submit a form on a webpage, the form data is submitted using a POST request.\n",
        "The common HTTP verbs are -\n",
        "\n",
        "1. GET - Query data form DB\n",
        "2. POST - Insert data into DB\n",
        "In python, we can use the simple and easy to use Requests library to make HTTP requests.\n",
        "\n",
        "Install the library by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LaU8KxoLQhd",
        "colab_type": "code",
        "outputId": "6bea7e17-cb30-4184-8818-2e32090f5e05",
        "colab": {}
      },
      "source": [
        "!pip install requests"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in c:\\users\\faisal ullah khan\\anaconda3\\lib\\site-packages (2.22.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\faisal ullah khan\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\faisal ullah khan\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\faisal ullah khan\\anaconda3\\lib\\site-packages (from requests) (2019.9.11)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\faisal ullah khan\\anaconda3\\lib\\site-packages (from requests) (1.24.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpoHLErrLQht",
        "colab_type": "text"
      },
      "source": [
        "- Now let us try to make some HTTP get requests using python by running the code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Hs43wQLQhw",
        "colab_type": "code",
        "outputId": "6f6c6ae3-9b31-4512-80b3-afc8719e7f7d",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "response=requests.get(\"http://httpbin.org/get\", )\n",
        "print(response.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"args\": {}, \n",
            "  \"headers\": {\n",
            "    \"Accept\": \"*/*\", \n",
            "    \"Accept-Encoding\": \"gzip, deflate\", \n",
            "    \"Host\": \"httpbin.org\", \n",
            "    \"User-Agent\": \"python-requests/2.22.0\", \n",
            "    \"X-Amzn-Trace-Id\": \"Root=1-5e3a50bd-85650acdee47cc4dd73ff527\"\n",
            "  }, \n",
            "  \"origin\": \"14.139.128.32\", \n",
            "  \"url\": \"http://httpbin.org/get\"\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDBP5bTZLQiB",
        "colab_type": "text"
      },
      "source": [
        "- Let's make another request this time with the get parameters <br>\n",
        "Run the cell below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06-VM382LQiG",
        "colab_type": "code",
        "outputId": "9aef2587-7a64-4968-8108-a3bd7d27d9e2",
        "colab": {}
      },
      "source": [
        "response=requests.get(\"http://httpbin.org/get\", params={'user':1})\n",
        "print(response.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"args\": {\n",
            "    \"user\": \"1\"\n",
            "  }, \n",
            "  \"headers\": {\n",
            "    \"Accept\": \"*/*\", \n",
            "    \"Accept-Encoding\": \"gzip, deflate\", \n",
            "    \"Host\": \"httpbin.org\", \n",
            "    \"User-Agent\": \"python-requests/2.22.0\", \n",
            "    \"X-Amzn-Trace-Id\": \"Root=1-5e3a50bd-3002e298d2fdc12836bb3348\"\n",
            "  }, \n",
            "  \"origin\": \"14.139.128.32\", \n",
            "  \"url\": \"http://httpbin.org/get?user=1\"\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrivnuSLLQiQ",
        "colab_type": "text"
      },
      "source": [
        "**Let's now try HTTP POST with Python requests**\n",
        "1. HTTP POST requets can be used to send data over HTTP requests.\n",
        "2. The data sent over a POST request can be in JSON format\n",
        "3. Read more about JSON [here](https://en.wikipedia.org/wiki/JSON#Example)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y5pI7fMLQiU",
        "colab_type": "code",
        "outputId": "e6301dde-47da-444e-e52b-f914e277670c",
        "colab": {}
      },
      "source": [
        "response=requests.post(\"http://httpbin.org/post\",json={\"user\":1})\n",
        "print(response.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"args\": {}, \n",
            "  \"data\": \"{\\\"user\\\": 1}\", \n",
            "  \"files\": {}, \n",
            "  \"form\": {}, \n",
            "  \"headers\": {\n",
            "    \"Accept\": \"*/*\", \n",
            "    \"Accept-Encoding\": \"gzip, deflate\", \n",
            "    \"Content-Length\": \"11\", \n",
            "    \"Content-Type\": \"application/json\", \n",
            "    \"Host\": \"httpbin.org\", \n",
            "    \"User-Agent\": \"python-requests/2.22.0\", \n",
            "    \"X-Amzn-Trace-Id\": \"Root=1-5e3a50be-e42c86a64378615576589ad3\"\n",
            "  }, \n",
            "  \"json\": {\n",
            "    \"user\": 1\n",
            "  }, \n",
            "  \"origin\": \"14.139.128.32\", \n",
            "  \"url\": \"http://httpbin.org/post\"\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqjhrBoGLQig",
        "colab_type": "text"
      },
      "source": [
        "**Elasticsearch API (continued)**\n",
        "***\n",
        "![IOTGW-DETAILS-HIGHLIGHT-MWHTTPCLIENT.png](attachment:IOTGW-DETAILS-HIGHLIGHT-MWHTTPCLIENT.png)\n",
        "***\n",
        "Now that we have figured out how to make GET and POST requests using python, we will try to insert some data into the Elasticsearch DB. In the process we will understand about the HTTP REST DB Client which is highlighted in the diagram above.\n",
        "\n",
        "Elasticsearch stores data in indices which are similar to a how data is stored in Tables in a Relational DB like MySQL.\n",
        "\n",
        "Let's call the index as sin6 as we are storing data from a sine wave. We can name it anything sensible. Another sensible name could be SensorName where SensorName is the name of the sensor from which data is inserted into the DB - e.g LightSensor, MoistureSensor, TemperatureSensor, etc.\n",
        "\n",
        "To insert data into an index called INDEXNAME, we post the data to the URL - http://localhost:9200/INDEXNAME/_doc\n",
        "\n",
        "Run the following cell to insert a JSON document containing a sine wave into the Elasticsearch DB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BytmGP1zLQij",
        "colab_type": "code",
        "outputId": "8e092727-a6d2-4070-d6f9-ee4e22b43056",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import paho.mqtt.client as mqtt\n",
        "import datetime\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plot\n",
        "\n",
        "def on_connect(client, userdata, flags, rc):\n",
        "    print(\"Connected\")\n",
        "    #Subscribing to topic\n",
        "    client.subscribe(\"python/sin6/#\")\n",
        "    \n",
        "def on_message(client, userdata, msg):\n",
        "    print(str(msg.payload))\n",
        "    hi = float(msg.payload)\n",
        "    document={\"raw_data\": hi,\"timestamp\":datetime.datetime.now().isoformat()}\n",
        "    ElasticsearchBaseURL=\"http://localhost:9200/\"\n",
        "    index=\"final6\"\n",
        "    url= ElasticsearchBaseURL + index + \"/_doc\"\n",
        "    print(\"Going to try http POST\")\n",
        "    print(document)\n",
        "    response=requests.post(url,json=document)\n",
        "    \n",
        "client = mqtt.Client()\n",
        "client.on_connect = on_connect\n",
        "client.on_message = on_message\n",
        "client.connect(\"localhost\", port=1883)          #connect to broker\n",
        "# client.username_pw_set(\"localhost\", password=password)    #set username and password\n",
        "\n",
        "client.loop_forever()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEnNoWsgLQix",
        "colab_type": "text"
      },
      "source": [
        "- **Now let us review the document stored in the elasticsearch DB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF2edUWbLQi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import paho.mqtt.client as mqttClient\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "index = 'final6'\n",
        "ElasticsearchBaseURL='http://localhost:9200/'\n",
        "response=requests.get(ElasticsearchBaseURL +index + \"/_search\")\n",
        "print(response.json())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdz_UkqcLQjC",
        "colab_type": "text"
      },
      "source": [
        "- **Summary**\n",
        "***\n",
        "1. Elasticsearch DB can be used to store and retireve JSON documents (in an INDEX) created from sensor data\n",
        "2. REST APIs like POST and GET are used to insert and query data from Elasticsearch DB into/from an INDEX\n",
        "3. HTTP DELETE method can be used to delete an INDEX\n",
        "4. To insert data we POST to the ElasticsearchBaseURL (default: http://localhost:9200) with INDEX name appended and _doc appended to the path i.e http://localhost:9200/INDEXNAME/_doc\n",
        "5. To query the data stored in an INDEX, we use the URL http://localhost:9200/INDEXNAME/_search\n",
        "6. To delete and INDEX, we make an HTTP DELETE request to the URL http://localhost:9200/INDEXNAME\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrXUu66TLQjG",
        "colab_type": "text"
      },
      "source": [
        "### Setting up Kibana\n",
        "***\n",
        "**What is Kibana used for?**\n",
        "> Kibana is a data visualization and management tool for Elasticsearch that provides real-time histograms, line graphs, pie charts, and maps. Kibana also includes advanced applications such as Canvas, which allows users to create custom dynamic infographics based on their data, and Elastic Maps for visualizing geospatial data.\n",
        "Visit the link to install Kibana on your system https://www.elastic.co/guide/en/kibana/current/targz.html\n",
        "\n",
        "- *Running Kibana*\n",
        "***\n",
        "> Launch ./elasticsearch from elasticsearch-x.y.z/bin/ Launch ./kibana from kibana-x.y.z/bin\n",
        "\n",
        "- *Test Kibana*\n",
        "***\n",
        "> Visit Kibana @ http://localhost:5601\n",
        "\n",
        "- To start the kibana service type <font color = red>sudo systemctl start kibana.service</font>\n",
        "\n",
        "**Add index pattern in Kibana management**\n",
        "***\n",
        "- Visit the Management page by clicking on the Management tab in the Left Sidebar.\n",
        "- Add a new index pattern called final6\n",
        "\n",
        "**Discover in Kibana**\n",
        "- Click on the Discover tab on the left sidebar.\n",
        "- Select the index pattern we just created - final6\n",
        "- Select the time range in the top right bar to last one hour\n",
        "- Now we should be able to see the data we just stored in Elasticsearch DB.\n",
        "***\n",
        "**The output of the above code as visualized using kibana is as follows:**\n",
        "***\n",
        "![Kibana.png](attachment:Kibana.png)\n",
        "***\n",
        "### Kibana Aggregations\n",
        "\n",
        "***\n",
        "- One of the key topics for understanding and using kibana are the aggregations.\n",
        "- They provide the base of all visualisations\n",
        "- The aggregations are primarily of 2 types:\n",
        "> 1. Bucket aggregations\n",
        "> 2. Metric aggregations\n",
        "\n",
        "**Bucket aggregations:**\n",
        "- Each bucket aggregation may contain many or single or none documents/data points\n",
        "- Buckets may overlap hence one doc/data point may be present in 2 or more buckets\n",
        "- After Bucket aggregation has been done some docs/data points might not be present in any of them\n",
        "***\n",
        "![Bucket%20aggregations.png](attachment:Bucket%20aggregations.png)\n",
        "***\n",
        "**Metric aggregation**\n",
        "- These aggregations are responsible for calculating a value for each bucket (based on the docs in each bucket)\n",
        "***\n",
        "![Metric%20aggregations.png](attachment:Metric%20aggregations.png)\n",
        "***\n",
        "- Now if we wish to visualize the aggregated data as a pie chart say then:\n",
        "***\n",
        "![Pie%20chart.png](attachment:Pie%20chart.png)\n",
        "***\n",
        "- Each bucket represents one slice of the pie\n",
        "- The size of each slice will be determined by the value of the metric aggregation\n",
        "\n",
        "***\n",
        "**The different types of Bucket and Metric aggregations are:**\n",
        "***\n",
        "**Bucket aggregations**\n",
        "> Histogram <br>\n",
        "Date Histogram <br>\n",
        "Range<br>\n",
        "Date Range<br>\n",
        "IPV4 Range<br>\n",
        "Filters<br>\n",
        "Geohash<br>\n",
        "Terms<br>\n",
        "Significant terms<br>\n",
        "***\n",
        "**Metric aggregations**\n",
        "> Count<br>\n",
        "Sum <br>\n",
        "Average<br>\n",
        "Median<br>\n",
        "Min<br>\n",
        "Max<br>\n",
        "Unique count<br>\n",
        "Standard Deviation<br>\n",
        "Percentiles<br>\n",
        "Percentile ranks<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1o2sBZPLQjK",
        "colab_type": "text"
      },
      "source": [
        "# 2.Data analysis and Signal Processing\n",
        "\n",
        "### Contents:\n",
        "- [Overview](#Overview)\n",
        "- [A glance at raw data](#A-glance-at-raw-data)\n",
        "- [Parameter Estimation and Machine State Identification Algorithms](#Parameter-Estimation-and-Machine-State-Identification-Algorithms)\n",
        "    - [1: Line Loader](#1:-Line-Loader)\n",
        "    - [2: Screen printer](#2:-Screen-printer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCzC7ukuLQjO",
        "colab_type": "text"
      },
      "source": [
        "### Overview\n",
        "***\n",
        "To get a better idea of the data analytics that we have to run on the data from the sensors, we need to have a complete architecture of a factory. Only by knowing how the various machines are interacting with each other, it will be possible for us to develop algorithms for say state detections etc.\n",
        "Here we will be using the example of vinyas factory whose architecture is as shown below:\n",
        "***\n",
        "![Layout.png](attachment:Layout.png)\n",
        "***\n",
        "The specific details are as follows:<br>\n",
        "1. Entry loader: vibration sensor.<br>\n",
        "2. Screen printer: proximity sensor (at exit), vibration sensor, current meter (single phase).<br>\n",
        "3. Pick-place machine #1: proximity sensor (at entry), vibration sensor, current meter (3 phase).<br>\n",
        "4. Pick-place machine #2: proximity sensor (at exit), vibration sensor, current meter (3 phase).<br>\n",
        "5. Reflow oven: proximity sensor (at entry and exit), vibration sensor, current meter (3 phase).<br>\n",
        "6. The first baking oven: temperature sensor, current meter (3 phase).<br>\n",
        "7. The second baking oven: temperature sensor, current meter (3 phase).<br>\n",
        "The ground floor of the factory was installed with current meters (6), vibration sensors (5), proximity sensors (5), and temperature sensors (2) as given above and at the locations as in Figure\n",
        "\n",
        "**Delays in machines**\n",
        "***\n",
        "![image.png](attachment:image.png)\n",
        "***\n",
        "### A glance at raw data\n",
        "***\n",
        "The following figure indicates data obtained from a pick-and-place machine. It clearly indicates the relationship between three modes of sensing – vibration, current, and proximity sensors.\n",
        "***\n",
        "![Data%20Analysis.png](attachment:Data%20Analysis.png)\n",
        "***\n",
        "In Figure above, the first provides the vibration sensor data (one component of the acceleration) on the pick-and-place machine 1 in the Vinyas factory. Note that there are two such machines. The second plot indicates the three currents (3 phase) drawn by this machine. The third plot is the proximity sensor data. The sensor is placed at the entry of the machine. When value is equal to 1, the board has been admitted into the machine.\n",
        "The above plot can be used to correlate different events. The easiest one to understand is when the board is admitted into the pick and place equipment – the proximity sensor value rises high. We can observe the surge in current drawn by the equipment and the considerable increase in vibration data when the machine starts operating on the PCB.\n",
        "Above is one such example of the raw data that is retrieved from the various sensors implemented on the production floor.\n",
        "With our current architecture, we have used various data analysis tools and techniques to infer the different events that take place during the production of PCBs across each machine on the assembly line and associate the events across the line to provide end-to-end traceability. As shown in the figure below, the correlation of data across machines enables boards to be tracked as they move along the assembly line.\n",
        "***\n",
        "![Data%20alalysis2.png](attachment:Data%20alalysis2.png)\n",
        "***\n",
        "Subsequently, based on those events, the various states of the machine can be identified. For example, we want to know when a board is being processed by a particular machine compared to when it is idle. For this, we have used python packages such as pandas, scipy (find peaks), numpy. From our current analysis algorithms, we have been able to infer the following parameters for each machine:\n",
        "1. Machine ID: Line-Loader, Screen-Printer, Pick-and-Place1, Pick-and-Place2\n",
        "2. Machine States: Idle, Loading, Printing, Processing, Maintenance, etc.\n",
        "3. Number of PCBs processed during the given period\n",
        "4. Arrival and departure instants of PCBs\n",
        "5. Delays in machines due to maintenance\n",
        "6. Machine Utilization Factor\n",
        "7. PCB processing time\n",
        "***\n",
        "### Parameter Estimation and Machine State Identification Algorithms\n",
        "***\n",
        "Below are the algorithms explained in detail, for each machine, on how we achieved the above parameters:\n",
        "***\n",
        "### 1: Line Loader\n",
        "***\n",
        "![Use%20this.png](attachment:Use%20this.png)\n",
        "***\n",
        "**Line loader board detections**\n",
        "***\n",
        "![Line%20loader%20boards%20detected.png](attachment:Line%20loader%20boards%20detected.png)\n",
        "***\n",
        "For the loader, vibration data was used. The parameters that were calculated for the loader were the number of boards (throughput) and the loading (processing) time per board. As the loader and the screen printer were powered by the same line in series, energy estimations were not performed for this machine. The magnitude of the acceleration in the X and Z axes was used. The Y component of acceleration was not used to prevent acceleration due to gravity from overshadowing the vibration in the other axes.\n",
        "From the raw vibration signals, the resultant along the X and Z axes was calculated. A centered rolling standard deviation with a window size of 100 samples (approx 1.3 seconds) was then applied to the signal. This window was selected as from the observation of raw data, the loading event was seen to last for approximately 2 seconds so the impulses of these events would be further enhanced. This processed signal can be seen in the figure above and is shown in orange. The green line in Figure (), shows the height threshold of 0.01 that is applied to detect peaks and those peaks were identified as loading events. The loading events are shown in the figure as blue stems. A time threshold constraint of 12 seconds was also applied to ensure that any spurious vibrations which exceed the height threshold immediately after any board detection were not counted as boards (false positives were removed). This time threshold of 12 seconds is identified on the basis that it takes 12 seconds for the screen printer to complete the processing of one board and hence the loader cannot push a board into the screen printer until that board is processed completely.\n",
        "The working times or the time taken for one loading event was calculated using the width of the peak of the processed signal measured at the threshold.\n",
        "*The algo developed for this is shown below:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTNxcmPILQjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.signal\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import sys\n",
        "\n",
        "## changing the figure size\n",
        "plt.rcParams[\"figure.figsize\"]=[15,5]\n",
        "\n",
        "raw_ld=pd.read_csv('loader.csv', usecols=['timestamp', 'data.ax', 'data.az'])\n",
        "raw_ld.sort_values(by=['timestamp'], inplace=True)\n",
        "raw_ld.reset_index(inplace=True)\n",
        "raw_ld.dropna(axis=0, inplace=True)\n",
        "raw_ld.timestamp=pd.to_datetime(raw_ld.timestamp)\n",
        "\n",
        "#Load LD data and plot\n",
        "raw_ld[\"acc\"] = ( raw_ld[\"data.ax\"]**2 + raw_ld[\"data.az\"]**2 ) ** 0.5\n",
        "acc=raw_ld[[\"timestamp\", \"acc\"]]\n",
        "acc.set_index('timestamp')\n",
        "test_ld=acc\n",
        "test_ld['acc_raw']=test_ld['acc']\n",
        "test_ld['acc']=pd.Series.to_frame(test_ld.acc.rolling(100, center=True).std())\n",
        "\n",
        "timethresh=12\n",
        "test_ld.insert(2,'state',0)\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(test_ld['timestamp'], test_ld['acc'])\n",
        "\n",
        "#Get boards from Loader\n",
        "board=scipy.signal.find_peaks(test_ld.acc, height=(0.01), distance=timethresh*72, width=1)\n",
        "differ=np.diff(board[0])\n",
        "differ=differ.tolist()\n",
        "\n",
        "for x in board[0]:\n",
        "    test_ld.at[x, 'state'] = 1\n",
        "\n",
        "ld_boards=test_ld[test_ld['state']==1]\n",
        "## creating another data frame which only has value of states as 1\n",
        "print('Boards detected in LD:', ld_boards.shape[0])\n",
        "# counting no. of rows via 'shape' of the new data frame to calculate the no. of boards\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "\n",
        "# ax1.plot(test_ld['timestamp'], test_ld['acc_raw'], 'green')\n",
        "ax1.plot(test_ld['timestamp'], np.ones(test_ld.shape[0])*0.01, 'green')\n",
        "ax1.plot(test_ld['timestamp'], test_ld['acc'], 'orange')\n",
        "\n",
        "# ax1.plot(test_ld['timestamp'], np.ones(test_ld.shape[0]*0.01), 'green')\n",
        "# ax1.xaxis.set_major_locator(mdates.DateFormatter('%H:%M'))\n",
        "\n",
        "ax1.set_xlabel('Time')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "ax2.stem(ld_boards['timestamp'], ld_boards['state'], 'b:')\n",
        "\n",
        "plt.title('Board Detections')\n",
        "\n",
        "loading_delays_rawdf=pd.DataFrame({\"sample_number\":board[0], \"working_time\":board[1]['widths']/72})\n",
        "\n",
        "LD_events=pd.DataFrame({\"timestamp\":test_ld.iloc[loading_delays_rawdf.sample_number].timestamp, \"event\":1, \"working_time\":(loading_delays_rawdf.working_time).tolist()})\n",
        "\n",
        "LD_events.index=LD_events.timestamp\n",
        "LD_events.drop('timestamp', axis=1, inplace=True)\n",
        "LD_events['energy']=float('nan')\n",
        "\n",
        "LD_events\n",
        "\n",
        "sns.distplot(LD_events.working_time)\n",
        "plt.title('Loader Loading Times Histogram')\n",
        "\n",
        "print('LD loading time mode: ', LD_events.working_time.mode().mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC9N3yK8LQjd",
        "colab_type": "text"
      },
      "source": [
        "### 2: Screen printer\n",
        "***\n",
        "![Screen%20Printer%20event%20detection.png](attachment:Screen%20Printer%20event%20detection.png)\n",
        "***\n",
        "![SP%20printing%20time.png](attachment:SP%20printing%20time.png)\n",
        "***\n",
        "![SP2.png](attachment:SP2.png)\n",
        "***\n",
        "The screen printer board detection algorithm uses a single-phase current data. It is found that the screen printer undergoes two events:\n",
        "1. Printing: When the screen printer applies solder paste on the PCBs and\n",
        "2. Cleaning: When the screen printer vacuum cleans the stencil\n",
        "\n",
        "Hence the parameters that were calculated for the screen printer were the number of boards (throughput), printing time, cleaning time, energy consumed during printing, energy consumed during cleaning and number of boards printed per cleaning event.\n",
        "For printing events, from the raw current data (orange waveform), a centered rolling sum with a window size of 6 samples (6 seconds, since current data is sampled every second) was applied to the signal. This processed signal can be seen in the figure above and is shown in blue. The window size of 6 seconds was selected because on observation from the raw data, it was found that a printing event in most cases took approximately 8 seconds. Taking a larger window close to 8, would increase the error as the rolling sum function starts rising earlier due to the inclusion of more data points. A window of 6 seconds included the right number of samples to get a large enough peak compared to the data points when the screen printer was idle, on which a height threshold between 11 and 15 was applied. A distance threshold of 12 seconds was applied to the find peaks function to ensure that any other peaks in the vicinity of the spikes in current during board processing were not incorrectly identified as boards. As can be seen in figure (), the blue signal includes at least 2 peaks in the processing part, but with the distance threshold and find peaks function, only the largest peak was identified as a printing event.\n",
        "For cleaning events, a centered rolling sum with a window size of 12 samples (12 seconds) was applied to the signal. This window was selected, as on observation from the raw data, a cleaning event took approximately 12 seconds. In this case, even though we had chosen the window to be equal to the average cleaning time observed, the processed signal in blue was seen to form a trapezoidal structure as can be seen in figure (). In figure (), it was also seen that the raw cleaning peak in orange was almost rectangular at the bottom. Hence due to the shape of the signals, in order to get the width of the peak identified, a height threshold of 60 was chosen strategically, in which it not only was able to detect peaks above the threshold, but also capture the entire width of the raw cleaning signal, hence giving us the working time of the cleaning event. The same distance threshold of 12 seconds was applied since a cleaning event took approximately 12 seconds.\n",
        "The working times were calculated using the widths of the peaks at the chosen threshold. The threshold was picked strategically, so that it captures the entire printing and cleaning time. As can be seen in the figures, the threshold on the processed signal captures all the spikes in current data, which was then attributed to a printing or cleaning event.\n",
        "In this case, the energy consumed during the events was calculated through integrating the current measured in that duration and multiplying that value with the constant voltage supply of 230 V. As we were able to segregate the printing events from the cleaning events and also able to identify when the screen printer was in an idle state (as the raw current data level is lower when the screen printer was not working on a board), the energy consumed during each machine state was found. Thereby, the total energy consumed by the machine for any window of time can be also be calculated.\n",
        "***\n",
        "*Algo developed is shown below*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUDNRWd7LQjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.signal\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"]=[15,5]\n",
        "raw_sp= pd.read_csv('screenprinter.csv', usecols =['timestamp', 'data.A1'])\n",
        "raw_sp.dropna(axis=0, inplace=True)\n",
        "raw_sp.sort_values(by=['timestamp'])\n",
        "raw_sp.reset_index(inplace=True)\n",
        "raw_sp['timestamp'] =  pd.to_datetime(raw_sp['timestamp'])\n",
        "test_sp=raw_sp\n",
        "\n",
        "#Get boards from Screenprinter\n",
        "test_sp=test_sp[['data.A1','timestamp']]\n",
        "# events=scipy.signal.find_peaks(test_sp['data.A1'], height=(2.22, 5), width=1)\n",
        "\n",
        "test_sp['sum']=pd.Series.to_frame(test_sp['data.A1'].rolling(6, center=True).sum())\n",
        "test_sp['sum_mean']=test_sp['sum'].rolling(12,center=True).mean()\n",
        "test_sp['sum_forcleaning']=pd.Series.to_frame(test_sp['data.A1'].rolling(12, center=True).sum())\n",
        "\n",
        "%matplotlib\n",
        "\n",
        "test_sp['idle']=2\n",
        "\n",
        "sptimethresh=30\n",
        "\n",
        "printing_delays_raw=scipy.signal.find_peaks(test_sp['sum'],height=(12.5, 15),distance=sptimethresh, width=1)\n",
        "printing_delays_raw_df=pd.DataFrame({\"sample_number\":printing_delays_raw[0], \"working_time\":printing_delays_raw[1]['widths']})\n",
        "cleaning_delays_raw=scipy.signal.find_peaks(test_sp['sum_forcleaning'], height=60, distance=sptimethresh, width=1)\n",
        "cleaning_delays_raw_df=pd.DataFrame({\"sample_number\":cleaning_delays_raw[0], \"working_time\":cleaning_delays_raw[1]['widths']})\n",
        "\n",
        "for index, i in enumerate(printing_delays_raw[0]):\n",
        "    test_sp.ix[int(printing_delays_raw[1]['left_ips'][index]) : int(printing_delays_raw[1]['right_ips'][index]), 'idle']=0\n",
        "\n",
        "for index, i in enumerate(cleaning_delays_raw[0]):\n",
        "    test_sp.ix[int(cleaning_delays_raw[1]['left_ips'][index]) : int(cleaning_delays_raw[1]['right_ips'][index]), 'idle']=0\n",
        "    \n",
        "idle_delays_raw=scipy.signal.find_peaks(test_sp['idle'], height=.5, width=1)\n",
        "idle_delays_raw_df=pd.DataFrame({\"sample_number\":idle_delays_raw[0], \"working_time\":idle_delays_raw[1]['widths']})\n",
        "\n",
        "SP_events=pd.DataFrame({\"timestamp\":test_sp.iloc[printing_delays_raw_df.sample_number].timestamp, \"event\":1, \"working_time\":printing_delays_raw_df.working_time.tolist()})\n",
        "cleanings=pd.DataFrame({\"timestamp\":test_sp.iloc[cleaning_delays_raw_df.sample_number].timestamp, \"event\":2, \"working_time\":cleaning_delays_raw_df.working_time.tolist()})\n",
        "\n",
        "SP_events.reset_index(inplace=True)\n",
        "cleanings.reset_index(inplace=True)\n",
        "\n",
        "idles=pd.DataFrame({\"timestamp\":test_sp.iloc[idle_delays_raw_df.sample_number].timestamp, \"event\":0, \"working_time\":idle_delays_raw_df.working_time.tolist()})\n",
        "idles.reset_index(inplace=True)\n",
        "\n",
        "for x, row in SP_events.iterrows():\n",
        "    SP_events.ix[x,'energy']=test_sp.ix[int(printing_delays_raw[1]['left_ips'][x]):int(printing_delays_raw[1]['right_ips'][x]), 'data.A1'].sum()*230/3600000\n",
        "    \n",
        "for x, row in cleanings.iterrows():\n",
        "    cleanings.ix[x,'energy']=test_sp.ix[int(cleaning_delays_raw[1]['left_ips'][x]):int(cleaning_delays_raw[1]['right_ips'][x]), 'data.A1'].sum()*230/3600000\n",
        "\n",
        "for x, row in idles.iterrows():\n",
        "    idles.ix[x,'energy']=test_sp.ix[int(idle_delays_raw[1]['left_ips'][x]):int(idle_delays_raw[1]['right_ips'][x]), 'data.A1'].sum()*230/3600000\n",
        "    \n",
        "SP_events.index=SP_events.timestamp\n",
        "SP_events.drop('timestamp', axis=1, inplace=True)\n",
        "SP_events.drop('index', axis=1, inplace=True)\n",
        "\n",
        "cleanings.index=cleanings.timestamp\n",
        "cleanings.drop('timestamp', axis=1, inplace=True)\n",
        "cleanings.drop('index', axis=1, inplace=True)\n",
        "\n",
        "idles.index=idles.timestamp\n",
        "idles.drop('timestamp', axis=1, inplace=True)\n",
        "idles.drop('index', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "SP_events=SP_events.append(cleanings)\n",
        "SP_events=SP_events.append(idles)\n",
        "\n",
        "print('Printing time Mode: ', SP_events.working_time[SP_events['event']==1].mean())\n",
        "print('Cleaning time Mode: ', SP_events.working_time[SP_events['event']==2].mode().mean())\n",
        "SP_events[SP_events.event==1].shape[0]\n",
        "\n",
        "SP1spower=SP_events[SP_events.event==1]['energy']*3600000/SP_events[SP_events.event==1]['working_time']\n",
        "SP1spower.mean()\n",
        "\n",
        "SP0spower=SP_events[SP_events.event==0]['energy']*3600000/SP_events[SP_events.event==0]['working_time']\n",
        "SP0spower.mean()\n",
        "\n",
        "SP_events[SP_events.event==1].shape[0]\n",
        "SP_events[SP_events.event==2].shape[0]\n",
        "\n",
        "plt.plot(test_sp['timestamp'], test_sp['data.A1'], 'orange')\n",
        "plt.stem(SP_events[SP_events.event==1].index, SP_events[SP_events.event==1].event*5, 'red')\n",
        "plt.plot(test_sp['timestamp'], test_sp['sum'], 'blue')\n",
        "#plt.stem(SP_events.index, SP_events.event==2, 'green')\n",
        "\n",
        "temp_sp=test_sp\n",
        "temp_sp.dropna(inplace=True)\n",
        "sns.distplot(temp_sp['sum_mean'].tolist())\n",
        "\n",
        "pkh_processed=pd.read_csv('sp_pkh_processed2019-07-02 12:51:40.300916.csv')\n",
        "pkh_processed.timestamp=pd.to_datetime(pkh_processed.timestamp)\n",
        "plt.stem(pkh_processed[pkh_processed.det_binry_sig==1].timestamp, pkh_processed[pkh_processed.det_binry_sig==1].det_binry_sig)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}